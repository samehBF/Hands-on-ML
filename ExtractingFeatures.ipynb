{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extracting Features**\n",
    "#### This exercise covers transforming the features with 1-of-k encoding also known as One Hot encoding. \n",
    "#### ** This exercise will cover: **\n",
    "+  ####*Part 1:* Featurize categorical data using 1-of-k encoding (One Hot encoding)\n",
    "+  ####*Part 2:* Construct an 1-of-k encoding dictionary\n",
    " \n",
    "#### Note that, for reference, you can look up the details of the relevant Spark methods in [Spark's Python API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) and the relevant NumPy methods in the [NumPy Reference](http://docs.scipy.org/doc/numpy/reference/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Part 1: Featurize categorical data using 1-of-k encoding **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1a) 1-of-k encoding **\n",
    "#### Categorical features refer to variables that can take one of a set of possible states at any given time.We would like to develop code to convert categorical features to numerical ones. In this exercise, we will work with a sample unlabeled dataset with four data points, with each data point representing a city. The first feature indicates the name of city (Beijing, Paris, Londre, New York); the second feature describes the temperature of the city (33., 15.); and the third (optional) feature describes how the city is polluted (very much, a little).\n",
    "#### In an 1-of-k approach, we want to represent each tuple of `(featureID, category)` via its own binary feature.  We can do this in Python by creating a dictionary that maps each tuple to a distinct integer, where the integer corresponds to a binary feature. To start, manually enter the entries in the OHE dictionary associated with the sample dataset by mapping the tuples to consecutive integers starting from zero,  ordering the tuples first by featureID and next by category.\n",
    "#### Later in this workshop, we'll use OHE dictionaries to transform data points into compact lists of features that can be used in machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data for manual OHE\n",
    "# Note: the first data point does not include any value for the optional third feature\n",
    "cityOne = [(0, 'Beijing'), (1, '33.'), (2, 'very much')]\n",
    "cityTwo = [(0, 'Paris'), (1, '15.')]\n",
    "cityThree =  [(0, 'London'), (1, '15.'), (2, 'a little')]\n",
    "cityFour =  [(0, 'New York'), (1, '10.'), (2, 'a little')]\n",
    "sampleDataRDD = sc.parallelize([cityOne, cityTwo, cityThree,cityFour])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "cityOHEDict = {}\n",
    "cityOHEDict[(0,'Beijing')] = 0\n",
    "cityOHEDict[(0,'Paris')] = 1\n",
    "cityOHEDict[(0,'London')] = 2\n",
    "cityOHEDict[(0,'New York')] = 3\n",
    "cityOHEDict[(1, '33.')] = 4\n",
    "cityOHEDict[(1, '15.')] = 5\n",
    "cityOHEDict[(1, '10.')] = 6\n",
    "cityOHEDict[(2, 'very much')] = 7\n",
    "cityOHEDict[(2, 'a little')] = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1b) Sparse vectors **\n",
    "#### Data points can typically be represented with a small number of non-zero 1-of-k encoding features relative to the total number of features that occur in the dataset.  By leveraging this sparsity and using sparse vector representations of 1-of-k encoding data, we can reduce storage and computational burdens.  Below are a few sample vectors represented as dense numpy arrays.  Use [SparseVector](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.linalg.SparseVector) to represent them in a sparse fashion, and verify that both the sparse and dense representations yield the same results when computing [dot products](http://en.wikipedia.org/wiki/Dot_product) (we will later use MLlib to train classifiers via gradient descent, and MLlib will need to compute dot products between SparseVectors and dense parameter vectors).\n",
    "#### Use `SparseVector(size, *args)` to create a new sparse vector where size is the length of the vector and args is either a dictionary, a list of (index, value) pairs, or two separate arrays of indices and values (sorted by index).  You'll need to create a sparse vector representation of each dense vector `aDense` and `bDense`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.mllib.linalg import SparseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.3\n",
      "7.3\n",
      "-0.5\n",
      "-0.5\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "aDense = np.array([0., 3., 0., 4.])\n",
    "aSparse = SparseVector(len(aDense), [1,3],[3.,4.])\n",
    "\n",
    "bDense = np.array([0., 0., 0., 1.])\n",
    "bSparse = SparseVector(len(bDense), [3],[1.])\n",
    "\n",
    "w = np.array([0.4, 3.1, -1.4, -.5])\n",
    "print aDense.dot(w)\n",
    "print aSparse.dot(w)\n",
    "print bDense.dot(w)\n",
    "print bSparse.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Sparse Vectors (1b)\n",
    "from test_helper import Test\n",
    "Test.assertTrue(isinstance(aSparse, SparseVector), 'aSparse needs to be an instance of SparseVector')\n",
    "Test.assertTrue(isinstance(bSparse, SparseVector), 'aSparse needs to be an instance of SparseVector')\n",
    "Test.assertTrue(aDense.dot(w) == aSparse.dot(w),\n",
    "                'dot product of aDense and w should equal dot product of aSparse and w')\n",
    "Test.assertTrue(bDense.dot(w) == bSparse.dot(w),\n",
    "                'dot product of bDense and w should equal dot product of bSparse and w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1c) 1-of-k encoding features as sparse vectors **\n",
    "#### Now let's see how we can represent the 1-of-k features for points in our sample dataset.  Using the mapping defined by the OHE dictionary from Part (1a), manually define 1-of-k features for the three sample data points using SparseVector format.  Any feature that occurs in a point should have the value 1.0.  For example, the `DenseVector` for a point with features 1 and 5 would be `[0.0, 1.0, 0.0, 0.0, 0.0,1.0, 0.0, 0.0,0.0,0.0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reminder of the sample features\n",
    "# cityOne = [(0, 'Beijing'), (1, '33.'), (2, 'very much')]\n",
    "# cityTwo = [(0, 'Paris'), (1, '15.')]\n",
    "# cityThree =  [(0, 'London'), (1, '15.'), (2, 'a little')]\n",
    "# cityFour =  [(0, 'New York'), (1, '10.'), (2, 'a little')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9,[0,4,7],[1.0,1.0,1.0])\n",
      "(9,[1,5],[1.0,1.0])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "cityOneOHEFeaturesManual = SparseVector(9, [0,4,7],[1.,1.,1.])\n",
    "cityTwoOHEFeaturesManual =  SparseVector(9, [1,5],[1.,1.])\n",
    "cityThreeOHEFeaturesManual =  SparseVector(9, [2,5,8],[1.,1.,1.])\n",
    "cityFourOHEFeaturesManual =  SparseVector(9, [3,6,8],[1.,1.,1.])\n",
    "print cityOneOHEFeaturesManual\n",
    "print cityTwoOHEFeaturesManual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST OHE Features as sparse vectors (1c)\n",
    "Test.assertTrue(isinstance(cityOneOHEFeatures, SparseVector),\n",
    "                'cityOneOHEFeatures needs to be a SparseVector')\n",
    "Test.assertTrue(isinstance(cityTwoOHEFeatures, SparseVector),\n",
    "                'cityTwoOHEFeatures needs to be a SparseVector')\n",
    "Test.assertTrue(isinstance(cityThreeOHEFeatures, SparseVector),\n",
    "                'cityThreeOHEFeatures needs to be a SparseVector')\n",
    "Test.assertTrue(isinstance(cityFourOHEFeatures, SparseVector),\n",
    "                'cityFourOHEFeatures needs to be a SparseVector')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1d) Define a OHE function **\n",
    "#### Next we will use the OHE dictionary from Part (1a) to programatically generate OHE features from the original categorical data.  First write a function called `oneHotEncoding` that creates OHE feature vectors in `SparseVector` format.  Then use this function to create OHE features for the first sample data point and verify that the result matches the result from Part (1c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 'Beijing'): 0, (0, 'London'): 2, (0, 'New York'): 3, (1, '10.'): 6, (2, 'a little'): 8, (1, '33.'): 4, (2, 'very much'): 7, (0, 'Paris'): 1, (1, '15.'): 5}\n",
      "(9,[0,4,7],[1.0,1.0,1.0])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def oneHotEncoding(rawFeats, OHEDictionary):\n",
    "    \"\"\"Produce a 1-of-k encoding from a list of features and an 1-of-k dictionary.\n",
    "\n",
    "    Note:\n",
    "        You should ensure that the indices used to create a SparseVector are sorted.\n",
    "\n",
    "    Args:\n",
    "        rawFeats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sampleOne)\n",
    "        OHEDictionary (dict): A mapping of (featureID, value) to unique integer.\n",
    "\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length numOHEFeats with indicies equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0.\n",
    "    \"\"\"\n",
    "    return SparseVector(len(OHEDictionary),sorted([(OHEDictionary[x],1.0) for x in rawFeats]))\n",
    "\n",
    "# Run oneHotEnoding on sampleOne\n",
    "print cityOHEDict\n",
    "cityOneOHEFeatures = oneHotEncoding(cityOne, cityOHEDict)\n",
    "\n",
    "print cityOneOHEFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Define an OHE Function (1d)\n",
    "Test.assertTrue(cityOneOHEFeatures == cityOneOHEFeaturesManual,\n",
    "                'cityOneOHEFeatures should equal cityOneOHEFeaturesManual')\n",
    "Test.assertEquals(cityOneOHEFeatures, SparseVector(9,[0,4,7],[1.0,1.0,1.0]),\n",
    "                  'incorrect value for cityOneOHEFeatures')\n",
    "Test.assertEquals(oneHotEncoding([(0, 'Beijing'), (1, '33.'),(2, 'very much')], cityOHEDict), \n",
    "                  SparseVector(9, [0,4,7], [1.0,1.0,1.0]),\n",
    "                  'incorrect definition for oneHotEncoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1e) Apply OHE to a dataset **\n",
    "#### Finally, use the function from Part (1d) to create OHE features for all 4 data points in the sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseVector(9, {0: 1.0, 4: 1.0, 7: 1.0}), SparseVector(9, {1: 1.0, 5: 1.0}), SparseVector(9, {2: 1.0, 5: 1.0, 8: 1.0}), SparseVector(9, {3: 1.0, 6: 1.0, 8: 1.0})]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "sampleOHEData = sampleDataRDD.map(lambda x: oneHotEncoding(x, cityOHEDict))\n",
    "print sampleOHEData.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Apply OHE to a dataset (1e)\n",
    "sampleOHEDataValues = sampleOHEData.collect( )\n",
    "Test.assertTrue(len(sampleOHEDataValues) == 4, 'sampleOHEData should have four elements')\n",
    "Test.assertEquals(sampleOHEDataValues[0], SparseVector(9, {0: 1.0, 4: 1.0, 7: 1.0}),\n",
    "                  'incorrect OHE for first sample')\n",
    "Test.assertEquals(sampleOHEDataValues[1], SparseVector(9, {1: 1.0, 5: 1.0}),\n",
    "                  'incorrect OHE for second sample')\n",
    "Test.assertEquals(sampleOHEDataValues[2], SparseVector(9, {2: 1.0, 5: 1.0, 8: 1.0}),\n",
    "                  'incorrect OHE for third sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Part 2: Construct an OHE dictionary **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2a) Pair RDD of `(featureID, category)` **\n",
    "#### To start, create an RDD of distinct `(featureID, category)` tuples. In our sample dataset, the 9 items in the resulting RDD are `(0, 'Beijing')`, `(0, 'Paris')`, `(0, 'London')`, `(0, 'New York')`,`(1, '33.')`, `(1, '15.')`, `(1, '10.')`, `(2, 'a little')`, `(2, 'very much')`. Notably `'15.'` appears twice in the dataset but only contributes one item to the RDD: `(1, '15')`.  Use [flatMap](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.flatMap) and [distinct](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.distinct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Beijing'), (0, 'London'), (0, 'New York'), (0, 'Paris'), (1, '10.'), (1, '15.'), (1, '33.'), (2, 'a little'), (2, 'very much')]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "sampleDistinctFeats = (sampleDataRDD\n",
    "                       .flatMap(lambda x: x).distinct())\n",
    "print sorted(sampleDistinctFeats.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Pair RDD of (featureID, category) (2a)\n",
    "Test.assertEquals(sorted(sampleDistinctFeats.collect()),\n",
    "                  [(0, 'Beijing'), (0, 'London'), (0, 'New York'), (0, 'Paris'), \n",
    "                   (1, '10.'), (1, '15.'), (1, '33.'), (2, 'a little'), (2, 'very much')],\n",
    "                  'incorrect value for sampleDistinctFeats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (2b) OHE Dictionary from distinct features **\n",
    "#### Next, create an `RDD` of key-value tuples, where each `(featureID, category)` tuple in `sampleDistinctFeats` is a key and the values are distinct integers ranging from 0 to (number of keys - 1).  Then convert this `RDD` into a dictionary, which can be done using the `collectAsMap` action.  Note that there is no unique mapping from keys to values, as all we require is that each `(featureID, category)` key be mapped to a unique integer between 0 and the number of keys.  In this exercise, any valid mapping is acceptable.  Use [zipWithIndex](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.zipWithIndex) followed by [collectAsMap](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.collectAsMap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 'Beijing'): 0, (0, 'London'): 1, (0, 'New York'): 2, (1, '10.'): 3, (2, 'a little'): 4, (1, '33.'): 5, (2, 'very much'): 6, (0, 'Paris'): 7, (1, '15.'): 8}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "sampleOHEDict = (sampleDistinctFeats\n",
    "                                    .zipWithIndex().collectAsMap())\n",
    "print sampleOHEDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Beijing'), (0, 'London'), (0, 'New York'), (0, 'Paris'), (1, '10.'), (1, '15.'), (1, '33.'), (2, 'a little'), (2, 'very much')]\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST OHE Dictionary from distinct features (2b)\n",
    "print sorted(sampleOHEDict.keys())\n",
    "Test.assertEquals(sorted(sampleOHEDict.keys()),\n",
    "                  [(0, 'Beijing'), (0, 'London'), (0, 'New York'), (0, 'Paris'), (1, '10.'), (1, '15.'), \n",
    "                   (1, '33.'), (2, 'a little'), (2, 'very much')],\n",
    "                  'sampleOHEDict has unexpected keys')\n",
    "Test.assertEquals(sorted(sampleOHEDict.values()), range(9), 'sampleOHEDict has unexpected values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2c) Automated creation of an OHE dictionary **\n",
    "#### Now use the code from Parts (2a) and (2b) to write a function that takes an input dataset and outputs an OHE dictionary.  Then use this function to create an OHE dictionary for the sample dataset, and verify that it matches the dictionary from Part (2b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 'Beijing'): 0, (0, 'London'): 1, (0, 'New York'): 2, (1, '10.'): 3, (2, 'a little'): 4, (1, '33.'): 5, (2, 'very much'): 6, (0, 'Paris'): 7, (1, '15.'): 8}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def createOneHotDict(inputData):\n",
    "    \"\"\"Creates a one-hot-encoder dictionary based on the input data.\n",
    "\n",
    "    Args:\n",
    "        inputData (RDD of lists of (int, str)): An RDD of observations where each observation is\n",
    "            made up of a list of (featureID, value) tuples.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are (featureID, value) tuples and map to values that are\n",
    "            unique integers.\n",
    "    \"\"\"\n",
    "    \n",
    "    DistinctFeats = (inputData\n",
    "                              .flatMap(lambda x: x).distinct())\n",
    "    \n",
    "    OHEDict = (DistinctFeats\n",
    "                            .zipWithIndex().collectAsMap())\n",
    "    \n",
    "    return OHEDict\n",
    "\n",
    "sampleOHEDictAuto = createOneHotDict(sampleDataRDD)\n",
    "print sampleOHEDictAuto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Automated creation of an OHE dictionary (2c)\n",
    "Test.assertEquals(sorted(sampleOHEDictAuto.keys()),\n",
    "                  [(0, 'Beijing'), (0, 'London'), (0, 'New York'), (0, 'Paris'), (1, '10.'), (1, '15.'), \n",
    "                   (1, '33.'), (2, 'a little'), (2, 'very much')],\n",
    "                  'sampleOHEDictAuto has unexpected keys')\n",
    "Test.assertEquals(sorted(sampleOHEDictAuto.values()), range(9),\n",
    "                  'sampleOHEDictAuto has unexpected values')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
