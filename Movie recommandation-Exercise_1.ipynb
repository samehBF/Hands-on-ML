{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# EXERCISE 1 - MOVIE RECOMMANDATION SYSTEM\n",
    "############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The purpuse of this excercise is to develop a system for movie recommandation \n",
    "\n",
    "# Used Dataset: A subset dataset of 500,000 movie ratings from the movielens 10M stable benchmark rating dataset (http://grouplens.org/datasets/movielens/10m/).  \n",
    "# The data set is included into your VM (/data/cs100/lab4/small)\n",
    "\n",
    "# We will follow these steps:\n",
    "        # - 1: Data Loading \n",
    "        # - 2: Features extraction\n",
    "        # - 3: Model implementation: The Naive approach\n",
    "        # - 4: Model implementation: The Collaborative Filtering approach\n",
    "        # - 5: Predict Films for yourself !\n",
    "        \n",
    "# Have a look at pySpark API: http://spark.apache.org/docs/latest/programming-guide.html#transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################################################\n",
    "# 1 - Data Loading\n",
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "baseDir = os.path.join('data')\n",
    "inputPath = os.path.join('cs100', 'lab4', 'small')\n",
    "\n",
    "ratingsFilename = os.path.join(baseDir, inputPath, 'ratings.dat.gz')\n",
    "moviesFilename = os.path.join(baseDir, inputPath, 'movies.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We read in each of the files and create an associated RDD\n",
    "\n",
    "numPartitions = 2\n",
    "rawRatings = sc.textFile(ratingsFilename).repartition(numPartitions)\n",
    "rawMovies = sc.textFile(moviesFilename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# Count Lines in each RDD\n",
    "rawRatings.<FILL IN> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawMovies.<FILL IN> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Each line in the ratings dataset (ratings.dat.gz) is formatted as: UserID::MovieID::Rating::Timestamp\n",
    "# Each line in the movies dataset (movies.dat) is formatted as: MovieID::Title::Genres\n",
    "\n",
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# Show the first line in each dataset\n",
    "\n",
    "rawRatings.<FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawMovies.<FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################################################\n",
    "# 2 - Feature Extraction\n",
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We read in each of the files and create an RDD consisting of parsed lines.\n",
    "\n",
    "# Use the defined functions to parse lines and transform them as following:\n",
    "## In ratings dataset: We create a tuple of (UserID, MovieID, Rating). We drop the timestamp.\n",
    "## In movies dataset: We create a tuple of (MovieID, Title). We drop the Genres. \n",
    "\n",
    "def get_ratings_tuple(entry):\n",
    "    items = entry.split('::')\n",
    "    return int(items[0]), int(items[1]), float(items[2])\n",
    "\n",
    "\n",
    "def get_movie_tuple(entry):\n",
    "    items = entry.split('::')\n",
    "    return int(items[0]), items[1]\n",
    "\n",
    "\n",
    "ratingsRDD = rawRatings.map(get_ratings_tuple).cache()\n",
    "moviesRDD = rawMovies.map(get_movie_tuple).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display the 2 first lines of each RDD\n",
    "moviesRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratingsRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################################################\n",
    "# 3 - Model implementation: The Naive approach\n",
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Approach: Recommend movies with the highest average rating and at least films having 500 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1- From ratingsRDD, Create an RDD that contiens Tuples with a movieID and all Its associated ratings\n",
    "## map: (UserID, MovieID, Rating)--> (MovieID, [Rating])\n",
    "## reduce: [(MovieID, [Rating1]),(MovieID, [Rating2])] --> [(MovieID, [Rating1, Rating2])]\n",
    "movieIDsWithRatingsRDD = (ratingsRDD\n",
    "                          .map(lambda(user_id, movie_id, rating):(movie_id,[rating]))\n",
    "                          .reduceByKey(lambda a,b: a+b))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# 2- Create a function that calculate the avearge rating and return a tuple (MovieID, (number of ratings, averageRating))\n",
    "## IN: (MovieID, [Rating1, Rating2])--> OUT: (MovieID, (number of ratings, averageRating))\n",
    "\n",
    "def getCountsAndAverages (RatingsTuple):\n",
    "    <FILL IN>\n",
    "    return <FILL IN>\n",
    "\n",
    "\n",
    "movieIDsWithAverageRatingsRDD = movieIDsWithRatingsRDD.<FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# 3- Use 'moviesRDD` to get the movie names for `movieIDsWithAvgRatingsRDD` and create tuples of the form :\n",
    "# (average rating, movie name, number of ratings)\n",
    "\n",
    "movieNameWithAvgRatingsRDD = (moviesRDD\n",
    "                              .<FILL IN>)\n",
    "\n",
    "# Print the 3 first lignes of the RDD:\n",
    "print 'movieNameWithAvgRatingsRDD: %s\\n' % movieNameWithAvgRatingsRDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply an RDD transformation to `movieNameWithAvgRatingsRDD` to limit the results to movies with\n",
    "# ratings having at least 500 people reviews and get the 20 first recommandations. \n",
    "# use the sortFunction to sort result.\n",
    "\n",
    "def sortFunction(tuple):\n",
    "    key = unicode('%.3f' % tuple[0])\n",
    "    value = tuple[1]\n",
    "    return (key + ' ' + value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "movieLimitedAndSortedByRatingRDD = (movieNameWithAvgRatingsRDD\n",
    "                                    .<FILL IN>\n",
    "                                    .sortBy (sortFunction,False)\n",
    "                                    )\n",
    "print 'Movies with highest ratings: %s' % movieLimitedAndSortedByRatingRDD.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################################################\n",
    "# 4 - Model implementation: The Collaborative Filtering\n",
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Spark also exposes some higher level functionality; in particular, Machine Learning using a component of Spark called MLlib. \n",
    "# In this part, you will learn how to use MLlib to make personalized movie recommendations using the movie data we have been analyzing.\n",
    "# We are going to use a technique called collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.1 - Befor using machine learning, we need to break up the ratingsRDD dataset into 3 parts\n",
    "\n",
    "    #### A training set (RDD), used to train the model\n",
    "    #### A validation set (RDD), used to choose the best model\n",
    "    #### A test set (RDD), used for experimentation\n",
    "    \n",
    "    # To randomly split the dataset into the multiple groups, we can use the pySpark randomSplit() transformation. \n",
    "    # randomSplit() takes a set of splits and a seed and returns multiple RDDs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingRDD, validationRDD, testRDD = ratingsRDD.randomSplit([6, 2, 2], seed=0L)\n",
    "\n",
    "print 'Training: %s, validation: %s, test: %s\\n' % (trainingRDD.count(),\n",
    "                                                    validationRDD.count(),\n",
    "                                                    testRDD.count())\n",
    "print trainingRDD.take(3)\n",
    "print validationRDD.take(3)\n",
    "print testRDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After splitting the dataset, your training set has about 293,000 entries and the validation and test sets \n",
    "# each have about 97,000 entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.2 Root Mean Square Error (RMSE):\n",
    "\n",
    "# In the next part, you will generate a few different models, and will need a way to decide which model is best. \n",
    "# We will use the Root Mean Square Error (RMSE) or Root Mean Square Deviation (RMSD) to compute the error of each model. \n",
    "## RMSE is a frequently used measure of the differences between values (sample and population values) predicted by a model \n",
    "## or an estimator and the values actually observed. \n",
    "## RMSD represents the sample standard deviation of the differences between predicted values and observed values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "import math\n",
    "\n",
    "def computeError(predictedRDD, actualRDD):\n",
    "    \"\"\" Compute the root mean squared error between predicted and actual\n",
    "    Args:\n",
    "        predictedRDD: predicted ratings for each movie and each user where each entry is in the form\n",
    "                      (UserID, MovieID, Rating)\n",
    "        actualRDD: actual ratings where each entry is in the form (UserID, MovieID, Rating)\n",
    "    Returns:\n",
    "        RSME (float): computed RSME value\n",
    "    \"\"\"\n",
    "    # Transform predictedRDD into the tuples of the form ((UserID, MovieID), Rating)\n",
    "    predictedReformattedRDD = (predictedRDD.<FILL IN>) \n",
    "\n",
    "    # Transform actualRDD into the tuples of the form ((UserID, MovieID), Rating)\n",
    "    actualReformattedRDD = (actualRDD.<FILL IN>) \n",
    "\n",
    "    # Compute the squared error for each matching entry (i.e., the same (User ID, Movie ID) in each\n",
    "    # RDD) in the reformatted RDDs using RDD transformtions - do not use collect()\n",
    "    squaredErrorsRDD = (predictedReformattedRDD\n",
    "                        .<FILL IN>\n",
    "                        .map (lambda (k,(a,b)):math.pow((a-b),2)))\n",
    "\n",
    "    # Compute the total squared error - do not use collect()\n",
    "    totalError = squaredErrorsRDD.reduce (lambda a,b: a+b)\n",
    "\n",
    "    # Count the number of entries for which you computed the total squared error\n",
    "    numRatings = squaredErrorsRDD.count()\n",
    "\n",
    "    # Using the total squared error and the number of entries, compute the RSME\n",
    "    return <FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.3 : Using the Alternating Least Squares (ALS.train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "validationForPredictRDD = validationRDD.<FILL IN>\n",
    "\n",
    "seed = 5L\n",
    "iterations = 5\n",
    "regularizationParameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.03\n",
    "\n",
    "minError = float('inf')\n",
    "bestRank = -1\n",
    "bestIteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(trainingRDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularizationParameter)\n",
    "    predictedRatingsRDD = model.predictAll(validationForPredictRDD)\n",
    "    error = computeError(predictedRatingsRDD, validationRDD)\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print 'For rank %s the RMSE is %s' % (rank, error)\n",
    "    if error < minError:\n",
    "        minError = error\n",
    "        bestRank = rank\n",
    "\n",
    "print 'The best model was trained with rank %s' % bestRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.4: Testing your model:\n",
    "# So far, we used the trainingRDD and validationRDD datasets to select the best model. \n",
    "# Since we used these two datasets to determine what model is best, we cannot use them \n",
    "# to test how good the model is - otherwise we would be very vulnerable to overfitting. \n",
    "# To decide how good our model is, we need to use the testRDD dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# train a model, using the trainingRDD, bestRank from previous part\n",
    "\n",
    "myModel = <FILL IN>\n",
    "testForPredictingRDD = testRDD.<FILL IN>\n",
    "predictedTestRDD = myModel.<FILL IN>\n",
    "\n",
    "testRMSE = computeError(testRDD, predictedTestRDD)\n",
    "\n",
    "print 'The model had a RMSE on the test set of %s' % testRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################################################\n",
    "# 5 -  TESTER LE MODEL: PREDIR DES FILMS POUR UN UTILISATEUR\n",
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5.1: Choose your movies:\n",
    "# To help you provide ratings for yourself, we have included the following code to list the names and movie IDs \n",
    "# of the 50 highest-rated movies from movieLimitedAndSortedByRatingRDD which we created in part 1 the lab.\n",
    "print 'Most rated movies:'\n",
    "print '(average rating, movie name, number of reviews)'\n",
    "for ratingsTuple in movieLimitedAndSortedByRatingRDD.take(10):\n",
    "    print ratingsTuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The user ID 0 is unassigned, so we will use it for your ratings. \n",
    "# We set the variable myUserID to 0 for you. Next, create a new RDD myRatingsRDD with your ratings for \n",
    "# at least 10 movie ratings. \n",
    "# Each entry should be formatted as (myUserID, movieID, rating) (i.e., each entry should be formatted in the same way as trainingRDD). \n",
    "# As in the original dataset, ratings should be between 1 and 5 (inclusive). If you have not seen at least 10 of these movies, \n",
    "# you can increase the parameter passed to take() in the above cell until there are 10 movies that you have seen \n",
    "# (or you can also guess what your rating would be for movies you have not seen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "# 5.2 - Create your dataSet:\n",
    "myUserID = 0\n",
    "\n",
    "# Note that the movie IDs are the *last* number on each line. A common error was to use the number of ratings as the movie ID.\n",
    "myRatedMovies = [\n",
    "     <FILL IN>\n",
    "    ]\n",
    "     # The format of each line is (myUserID, movie ID, your rating)\n",
    "     # For example, to give the movie \"Star Wars: Episode IV - A New Hope (1977)\" a five rating, you would add the following line:\n",
    "\n",
    "\n",
    "myRatingsRDD = sc.parallelize(myRatedMovies)\n",
    "print 'My movie ratings: %s' % myRatingsRDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# 5.3 - Add Your Movies to Training Dataset\n",
    "# Spark's union() transformation combines two RDDs; use union() to create a new training dataset that includes your ratings and the data in the original training dataset.Â¶\n",
    "trainingWithMyRatingsRDD = myRatingsRDD.<FILL IN>\n",
    "\n",
    "print ('The training dataset now has %s more entries than the original training dataset' %\n",
    "       (trainingWithMyRatingsRDD.count() - trainingRDD.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# 5.4- Train a Model with Your Ratings and the parameters you used previously for the best model \n",
    "\n",
    "myRatingsModel = ALS.train(trainingWithMyRatingsRDD, bestRank, <FILL IN>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5.5- Check RMSE for the New Model with Your Ratings\n",
    "\n",
    "predictedTestMyRatingsRDD = myRatingsModel.predictAll(testForPredictingRDD)\n",
    "testRMSEMyRatings = computeError(testRDD, predictedTestMyRatingsRDD)\n",
    "print 'The model had a RMSE on the test set of %s' % testRMSEMyRatings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5.6 - Predict your rating: We predict your rating for films you did not see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "\n",
    "# Get an RDD with only the movies I did not rate Then run predictAll()\n",
    "MyUnratedMoviesRDD = (moviesRDD\n",
    "                      .<FILL IN>)\n",
    "                     \n",
    "predictedRDD = myRatingsModel.<FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5.7 - Display the predicted rating: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movieCountsRDD = movieIDsWithAverageRatingsRDD.map(lambda (movie_id, (ratings, average)):(movie_id, ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform predictedRatingsRDD into an RDD with entries that are pairs of the form (Movie ID, Predicted Rating)\n",
    "predictedRDD = predictedRatingsRDD.map(lambda (uid, movie_id, rating): (movie_id, rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# Use RDD transformations with predictedRDD and movieCountsRDD to yield an RDD with tuples of the form (Movie ID, (Predicted Rating, number of ratings))\n",
    "predictedWithCountsRDD = ((predictedRDD.<FILL IN>))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "# Use RDD transformations with PredictedWithCountsRDD and moviesRDD to yield an RDD with tuples of the form (Predicted Rating, Movie Name, number of ratings), for movies with more than 75 ratings\n",
    "ratingsWithNamesRDD = (predictedWithCountsRDD\n",
    "                        .<FILL IN>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictedHighestRatedMovies = ratingsWithNamesRDD.takeOrdered(10, key=lambda x: -x[0])\n",
    "print ('My highest rated movies as predicted (for movies with more than 75 reviews):\\n%s' %\n",
    "        '\\n'.join(map(str, predictedHighestRatedMovies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
